<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>A primer on PCA | Edo</title>
    <link>https://edoardocostantini.github.io/category/a-primer-on-pca/</link>
      <atom:link href="https://edoardocostantini.github.io/category/a-primer-on-pca/index.xml" rel="self" type="application/rss+xml" />
    <description>A primer on PCA</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Thu, 04 Aug 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://edoardocostantini.github.io/media/icon_hubc644763d821b4643633e77d54abca59_619947_512x512_fill_lanczos_center_3.png</url>
      <title>A primer on PCA</title>
      <link>https://edoardocostantini.github.io/category/a-primer-on-pca/</link>
    </image>
    
    <item>
      <title>Principal covariates regression in R</title>
      <link>https://edoardocostantini.github.io/post/pcovr/</link>
      <pubDate>Thu, 04 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://edoardocostantini.github.io/post/pcovr/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;1&lt;/span&gt; Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#r-code-notes&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2&lt;/span&gt; R code notes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tldr-just-give-me-the-code&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3&lt;/span&gt; TL;DR, just give me the code!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34; number=&#34;1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; Introduction&lt;/h1&gt;
&lt;p&gt;Principal covariates regression is a method to analyze the relationship between sets of multivariate data in the presence of highly-collinear variables.
Compared to regular principal component regression, principal covariates regression PCovR extracts components that account for much of the variability in a set of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; variables and that correlated well with a set of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; variables.
For more information, I recommend reading &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-vervloet2015pcovr&#34; role=&#34;doc-biblioref&#34;&gt;Vervloet et al.&lt;/a&gt; (&lt;a href=&#34;#ref-vervloet2015pcovr&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; and &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-de1992principal&#34; role=&#34;doc-biblioref&#34;&gt;De Jong and Kiers&lt;/a&gt; (&lt;a href=&#34;#ref-de1992principal&#34; role=&#34;doc-biblioref&#34;&gt;1992&lt;/a&gt;)&lt;/span&gt;.
In this post, you can find my R code notes on this method.
In these notes, I show the computations used by the &lt;code&gt;PCovR&lt;/code&gt; R-package to perform the method.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-code-notes&#34; class=&#34;section level1&#34; number=&#34;2&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; R code notes&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Set up environment -----------------------------------------------------------

    # Load pacakge that implements this method
    library(&amp;quot;PCovR&amp;quot;, verbose = FALSE, quietly = TRUE)

    # Load example data from PCovR package
    data(alexithymia)

    # Explore its scale
    colMeans(alexithymia$X)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          confused       right words        sensations          describe 
##         1.8196721         1.7950820         0.5983607         2.2213115 
##  analyze problems             upset           puzzled        let happen 
##         2.5081967         1.6065574         1.1393443         1.2622951 
##          identify         essential feel about people     describe more 
##         1.6393443         2.7131148         1.7213115         1.0081967 
##          going on         why angry  daily activities     entertainment 
##         0.9836066         1.2540984         1.6639344         1.6967213 
##   reveal feelings             close            useful   hidden meanings 
##         1.6475410         2.8442623         2.4672131         1.2131148&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;    colMeans(alexithymia$Y)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    CES-D      RSE 
## 16.46721 31.37295&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;    apply(alexithymia$X, 2, var)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          confused       right words        sensations          describe 
##          1.388701          1.635348          1.151402          1.479542 
##  analyze problems             upset           puzzled        let happen 
##          1.161089          1.678634          1.294472          1.302534 
##          identify         essential feel about people     describe more 
##          1.620919          1.231066          1.475410          1.363569 
##          going on         why angry  daily activities     entertainment 
##          1.470803          1.496884          1.514226          1.601477 
##   reveal feelings             close            useful   hidden meanings 
##          2.097886          1.240008          1.193131          1.045116&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;    apply(alexithymia$Y, 2, var)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     CES-D       RSE 
## 118.35016  37.24199&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;    # Subset data
    X_raw &amp;lt;- alexithymia$X
    y_raw &amp;lt;- alexithymia$Y[, 1, drop = FALSE]

    # Define paramters that can be useful
    n &amp;lt;- nrow(X_raw)
    p &amp;lt;- ncol(X_raw)

    # Scale data
    X &amp;lt;- scale(X_raw)# * (n - 1) / n
    y &amp;lt;- scale(y_raw)# * (n - 1) / n

    # Define parameters
    alpha &amp;lt;- .5 # weighting parameter
    npcs &amp;lt;- 5

# Estimation -------------------------------------------------------------------

    # Estimate with PCovR function
    out &amp;lt;- PCovR::pcovr_est(
        X = X,
        Y = y,
        a = alpha,
        r = npcs # fixed number of components
    )

    # Estimate manually (Vervolet version)
    Hx &amp;lt;- X %*% solve(t(X) %*% X) %*% t(X)
    G_vv &amp;lt;- alpha * X %*% t(X) / sum(X^2) + (1 - alpha) * Hx %*% y %*% t(y) %*% Hx / sum(y^2)
    EG_vv &amp;lt;- eigen(G_vv) # eigen-decomposition of matrix
    T_vv &amp;lt;- EG_vv$vectors[, 1:npcs]

# Compare results --------------------------------------------------------------

    # T scores
    Ts &amp;lt;- list(
        PCovR = head(out$Te),
        PCovR_man = head(X %*% out$W),
        Vervolet = head(T_vv)
    )

    # Weights
    W &amp;lt;- list(
        PCovR = out$W,
        Vervolet = solve(t(X) %*% X) %*% t(X) %*% T_vv
    )

    # Px
    ( t(out$Te) %*% X )[, 1:5]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        confused right words sensations   describe analyze problems
## [1,] -8.4662585  -7.3375812 -2.2012950  6.1597661        0.4271093
## [2,]  3.3642487  -2.5380829 -0.2684529  4.9595077        6.2443158
## [3,] -1.4118650  -4.4348404  1.4484525  1.8944371       -3.1435113
## [4,]  1.1136577   1.0030862  2.0443923 -3.5188316        0.5622115
## [5,]  0.8172586   0.7913444  5.2341517  0.5130866       -5.2948505&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;    ( t(out$W) %*% t(X) %*% X )[, 1:5]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        confused right words sensations   describe analyze problems
## [1,] -8.4662585  -7.3375812 -2.2012950  6.1597661        0.4271093
## [2,]  3.3642487  -2.5380829 -0.2684529  4.9595077        6.2443158
## [3,] -1.4118650  -4.4348404  1.4484525  1.8944371       -3.1435113
## [4,]  1.1136577   1.0030862  2.0443923 -3.5188316        0.5622115
## [5,]  0.8172586   0.7913444  5.2341517  0.5130866       -5.2948505&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;    out$Px[, 1:5]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        confused right words sensations   describe analyze problems
## [1,] -8.4662585  -7.3375812 -2.2012950  6.1597661        0.4271093
## [2,]  3.3642487  -2.5380829 -0.2684529  4.9595077        6.2443158
## [3,] -1.4118650  -4.4348404  1.4484525  1.8944371       -3.1435113
## [4,]  1.1136577   1.0030862  2.0443923 -3.5188316        0.5622115
## [5,]  0.8172586   0.7913444  5.2341517  0.5130866       -5.2948505&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;    # Py
    cbind(
        Py = out$Py,
        TtY = t(out$Te) %*% y,
        WtXtY = t(out$W) %*% t(X) %*% y
    )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           CES-D      CES-D      CES-D
## [1,] -6.9315017 -6.9315017 -6.9315017
## [2,]  0.7212995  0.7212995  0.7212995
## [3,]  1.1114400  1.1114400  1.1114400
## [4,] -0.2349069 -0.2349069 -0.2349069
## [5,] -0.5126823 -0.5126823 -0.5126823&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;    # B
    cbind(
        B = drop(out$B),
        WPY = drop(out$W %*% out$Py),
        WWtXtY = drop(out$W %*% t(out$W) %*% t(X) %*% y)
    )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                  B          WPY       WWtXtY
##  [1,]  0.383110912  0.383110912  0.383110912
##  [2,]  0.019216602  0.019216602  0.019216602
##  [3,] -0.032288901 -0.032288901 -0.032288901
##  [4,] -0.016670641 -0.016670641 -0.016670641
##  [5,]  0.086442108  0.086442108  0.086442108
##  [6,] -0.185643598 -0.185643598 -0.185643598
##  [7,]  0.145228530  0.145228530  0.145228530
##  [8,] -0.016889454 -0.016889454 -0.016889454
##  [9,]  0.019540943  0.019540943  0.019540943
## [10,] -0.129790008 -0.129790008 -0.129790008
## [11,]  0.011837598  0.011837598  0.011837598
## [12,] -0.060783224 -0.060783224 -0.060783224
## [13,]  0.214728328  0.214728328  0.214728328
## [14,]  0.182671533  0.182671533  0.182671533
## [15,]  0.044201180  0.044201180  0.044201180
## [16,] -0.002997744 -0.002997744 -0.002997744
## [17,]  0.041239398  0.041239398  0.041239398
## [18,]  0.035879278  0.035879278  0.035879278
## [19,] -0.131120013 -0.131120013 -0.131120013
## [20,] -0.049644574 -0.049644574 -0.049644574&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Maximum likelihood tuning of alpha -------------------------------------------

    # Fit PCovR
    pcovr_out &amp;lt;- pcovr(
        X = X_raw,
        Y = y_raw,
        rot = &amp;quot;none&amp;quot;,
        R = npcs, # fixed number of components
        modsel = &amp;quot;seq&amp;quot; # fastest option
    )

    # Compute error ratio with function
    err &amp;lt;- ErrorRatio(
        X = X,
        Y = y,
        Rmin = npcs,
        Rmax = npcs
    )

    # Compute error ratio components
    lm_mod &amp;lt;- lm(y ~ -1 + X)
    ery &amp;lt;- 1 - summary(lm_mod)$r.squared

    Rmin &amp;lt;- npcs
    Rmax &amp;lt;- npcs
    sing &amp;lt;- svd(X)
    vec &amp;lt;- Rmin:Rmax
    vec &amp;lt;- c(vec[1] - 1, vec, vec[length(vec)] + 1)
    VAF &amp;lt;- c(0, cumsum(sing$d^2) / sum(sing$d^2))
    VAF &amp;lt;- VAF[vec + 1]
    scr &amp;lt;- array(NA, c(1, length(vec)))
    for (u in 2:(length(vec) - 1)) {
        scr[, u] &amp;lt;- (VAF[u] - VAF[u - 1]) / (VAF[u + 1] - VAF[u])
    }
    erx &amp;lt;- 1 - VAF[which.max(scr)]

    # Find alpha ML
    alpha_ML &amp;lt;- sum(X^2) / (sum(X^2) + sum(y^2) * erx / ery)

    # Compare to one found by package
    pcovr_out$a - alpha_ML&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;tldr-just-give-me-the-code&#34; class=&#34;section level1&#34; number=&#34;3&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;3&lt;/span&gt; TL;DR, just give me the code!&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Set up environment -----------------------------------------------------------

    # Load pacakge that implements this method
    library(&amp;quot;PCovR&amp;quot;, verbose = FALSE, quietly = TRUE)

    # Load example data from PCovR package
    data(alexithymia)

    # Explore its scale
    colMeans(alexithymia$X)
    colMeans(alexithymia$Y)

    apply(alexithymia$X, 2, var)
    apply(alexithymia$Y, 2, var)

    # Subset data
    X_raw &amp;lt;- alexithymia$X
    y_raw &amp;lt;- alexithymia$Y[, 1, drop = FALSE]

    # Define paramters that can be useful
    n &amp;lt;- nrow(X_raw)
    p &amp;lt;- ncol(X_raw)

    # Scale data
    X &amp;lt;- scale(X_raw)# * (n - 1) / n
    y &amp;lt;- scale(y_raw)# * (n - 1) / n

    # Define parameters
    alpha &amp;lt;- .5 # weighting parameter
    npcs &amp;lt;- 5

# Estimation -------------------------------------------------------------------

    # Estimate with PCovR function
    out &amp;lt;- PCovR::pcovr_est(
        X = X,
        Y = y,
        a = alpha,
        r = npcs # fixed number of components
    )

    # Estimate manually (Vervolet version)
    Hx &amp;lt;- X %*% solve(t(X) %*% X) %*% t(X)
    G_vv &amp;lt;- alpha * X %*% t(X) / sum(X^2) + (1 - alpha) * Hx %*% y %*% t(y) %*% Hx / sum(y^2)
    EG_vv &amp;lt;- eigen(G_vv) # eigen-decomposition of matrix
    T_vv &amp;lt;- EG_vv$vectors[, 1:npcs]

# Compare results --------------------------------------------------------------

    # T scores
    Ts &amp;lt;- list(
        PCovR = head(out$Te),
        PCovR_man = head(X %*% out$W),
        Vervolet = head(T_vv)
    )

    # Weights
    W &amp;lt;- list(
        PCovR = out$W,
        Vervolet = solve(t(X) %*% X) %*% t(X) %*% T_vv
    )

    # Px
    ( t(out$Te) %*% X )[, 1:5]
    ( t(out$W) %*% t(X) %*% X )[, 1:5]
    out$Px[, 1:5]

    # Py
    cbind(
        Py = out$Py,
        TtY = t(out$Te) %*% y,
        WtXtY = t(out$W) %*% t(X) %*% y
    )

    # B
    cbind(
        B = drop(out$B),
        WPY = drop(out$W %*% out$Py),
        WWtXtY = drop(out$W %*% t(out$W) %*% t(X) %*% y)
    )

# Maximum likelihood tuning of alpha -------------------------------------------

    # Fit PCovR
    pcovr_out &amp;lt;- pcovr(
        X = X_raw,
        Y = y_raw,
        rot = &amp;quot;none&amp;quot;,
        R = npcs, # fixed number of components
        modsel = &amp;quot;seq&amp;quot; # fastest option
    )

    # Compute error ratio with function
    err &amp;lt;- ErrorRatio(
        X = X,
        Y = y,
        Rmin = npcs,
        Rmax = npcs
    )

    # Compute error ratio components
    lm_mod &amp;lt;- lm(y ~ -1 + X)
    ery &amp;lt;- 1 - summary(lm_mod)$r.squared

    Rmin &amp;lt;- npcs
    Rmax &amp;lt;- npcs
    sing &amp;lt;- svd(X)
    vec &amp;lt;- Rmin:Rmax
    vec &amp;lt;- c(vec[1] - 1, vec, vec[length(vec)] + 1)
    VAF &amp;lt;- c(0, cumsum(sing$d^2) / sum(sing$d^2))
    VAF &amp;lt;- VAF[vec + 1]
    scr &amp;lt;- array(NA, c(1, length(vec)))
    for (u in 2:(length(vec) - 1)) {
        scr[, u] &amp;lt;- (VAF[u] - VAF[u - 1]) / (VAF[u + 1] - VAF[u])
    }
    erx &amp;lt;- 1 - VAF[which.max(scr)]

    # Find alpha ML
    alpha_ML &amp;lt;- sum(X^2) / (sum(X^2) + sum(y^2) * erx / ery)

    # Compare to one found by package
    pcovr_out$a - alpha_ML&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34;&gt;
&lt;div id=&#34;ref-de1992principal&#34; class=&#34;csl-entry&#34;&gt;
De Jong, Sijmen, and Henk AL Kiers. 1992. &lt;span&gt;“Principal Covariates Regression: Part i. Theory.”&lt;/span&gt; &lt;em&gt;Chemometrics and Intelligent Laboratory Systems&lt;/em&gt; 14 (1-3): 155–64.
&lt;/div&gt;
&lt;div id=&#34;ref-vervloet2015pcovr&#34; class=&#34;csl-entry&#34;&gt;
Vervloet, Marlies, Henk AL Kiers, Wim Van den Noortgate, and Eva Ceulemans. 2015. &lt;span&gt;“PCovR: An r Package for Principal Covariates Regression.”&lt;/span&gt; &lt;em&gt;Journal of Statistical Software&lt;/em&gt; 65: 1–14.
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
