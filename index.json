[{"authors":null,"categories":null,"content":"I‚Äôm a PhD researcher at Tilburg University. Here I will write a more in-depth bio.\n  Download my resum√©.\n","date":1647216000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1648903078,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://symphonious-crostata-aa195e.netlify.app/author/edoardo-costantini-edo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/edoardo-costantini-edo/","section":"authors","summary":"I‚Äôm a PhD researcher at Tilburg University. Here I will write a more in-depth bio.\n  Download my resum√©.","tags":null,"title":"Edoardo Costantini (Edo)","type":"authors"},{"authors":null,"categories":null,"content":"Âê≥ÊÅ©ÈÅî is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"da99cb196019cc5857b9b3e950397ca9","permalink":"https://symphonious-crostata-aa195e.netlify.app/author/%E5%90%B3%E6%81%A9%E9%81%94/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","section":"authors","summary":"Âê≥ÊÅ©ÈÅî is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"Âê≥ÊÅ©ÈÅî","type":"authors"},{"authors":null,"categories":null,"content":"   Table of Contents  What you will learn Program overview Courses in this program Meet your instructor FAQs    What you will learn  Fundamental Python programming skills Statistical concepts and how to apply them in practice Gain experience with the Scikit, including data visualization with Plotly and data wrangling with Pandas  Program overview The demand for skilled data science practitioners is rapidly growing. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi.\nCourses in this program  Python basics Build a foundation in Python.   Visualization Learn how to visualize data with Plotly.   Statistics Introduction to statistics for data science.   Meet your instructor Edoardo Costantini (Edo) FAQs Are there prerequisites? There are no prerequisites for the first course.\n How often do the courses run? Continuously, at your own pace.\n  Begin the course   ","date":1611446400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1611446400,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"https://symphonious-crostata-aa195e.netlify.app/courses/example/","publishdate":"2021-01-24T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"An example of using Wowchemy's Book layout for publishing online courses.","tags":null,"title":"üìä Learn Data Science","type":"book"},{"authors":null,"categories":null,"content":"Build a foundation in Python.\n  1-2 hours per week, for 8 weeks\nLearn   Quiz What is the difference between lists and tuples? Lists\n Lists are mutable - they can be changed Slower than tuples Syntax: a_list = [1, 2.0, \u0026#39;Hello world\u0026#39;]  Tuples\n Tuples are immutable - they can‚Äôt be changed Tuples are faster than lists Syntax: a_tuple = (1, 2.0, \u0026#39;Hello world\u0026#39;)   Is Python case-sensitive? Yes\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"17a31b92253d299002593b7491eedeea","permalink":"https://symphonious-crostata-aa195e.netlify.app/courses/example/python/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/example/python/","section":"courses","summary":"Build a foundation in Python.\n","tags":null,"title":"Python basics","type":"book"},{"authors":null,"categories":null,"content":"Learn how to visualize data with Plotly.\n  1-2 hours per week, for 8 weeks\nLearn   Quiz When is a heatmap useful? Lorem ipsum dolor sit amet, consectetur adipiscing elit.\n Write Plotly code to render a bar chart import plotly.express as px data_canada = px.data.gapminder().query(\u0026#34;country == \u0026#39;Canada\u0026#39;\u0026#34;) fig = px.bar(data_canada, x=\u0026#39;year\u0026#39;, y=\u0026#39;pop\u0026#39;) fig.show()  ","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"1b341b3479c8c6b1f807553b77e21b7c","permalink":"https://symphonious-crostata-aa195e.netlify.app/courses/example/visualization/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/example/visualization/","section":"courses","summary":"Learn how to visualize data with Plotly.\n","tags":null,"title":"Visualization","type":"book"},{"authors":null,"categories":null,"content":"Introduction to statistics for data science.\n  1-2 hours per week, for 8 weeks\nLearn The general form of the normal probability density function is:\n$$ f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi} } e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2} $$\n The parameter $\\mu$ is the mean or expectation of the distribution. $\\sigma$ is its standard deviation. The variance of the distribution is $\\sigma^{2}$.   Quiz What is the parameter $\\mu$? The parameter $\\mu$ is the mean or expectation of the distribution.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"6f4078728d71b1b791d39f218bf2bdb1","permalink":"https://symphonious-crostata-aa195e.netlify.app/courses/example/stats/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/example/stats/","section":"courses","summary":"Introduction to statistics for data science.\n","tags":null,"title":"Statistics","type":"book"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy‚Äôs Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://symphonious-crostata-aa195e.netlify.app/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Edoardo Costantini (Edo)"],"categories":["Tutorials","Drafts"],"content":"   1 Introduction 2 Learn by coding  2.1 Example 2.2 Computing the weighted covariance matrix manually  2.2.1 Exploring the stats::cov.wt() function code 2.2.2 Reproducing the internal steps  2.3 Mathematical formula and alternative R computations  2.3.1 Unbiased weighted covariance matrix 2.3.2 Maximum Likelihood weighted covariance matrix  2.4 Relationship with the matrix of sufficient statistics  3 TL;DR, just give me the code!   1 Introduction In a sample made of groups of different sizes, descriptive statistics like the mean and the covariance between variables can be computed by assigning proper weights to account for the difference in group sizes. Wights are generally normalized (i.e., \\(\\sum_{i = 1}^{n} w_i = 1\\)).\n 2 Learn by coding 2.1 Example Now, let‚Äôs consider a very simple example. Say that you have a dataset with two variables and that you have a vector of weights defining how important each observation should be.\n# Initial simple example ------------------------------------------------------- # Get the dataset used in the example of stats::cov.wt() xy \u0026lt;- cbind(x = 1:10, y = c(1:3, 8:5, 8:10)) # Define non-negative weights (as in example of stats::cov.wt()) wi \u0026lt;- c(0,0,0,1,1,1,1,1,0,0) # Get the weighted estimate with the default methods covwt_stats \u0026lt;- stats::cov.wt(xy, wt = wi) # i.e. method = \u0026#34;unbiased\u0026#34; # Compare unweighted and weighted means data.frame(uw = colMeans(xy), select = colMeans(xy[wi == 1, ]), wg = covwt_stats$center) ## uw select wg ## x 5.5 6.0 6.0 ## y 5.9 6.8 6.8  # Compare unweighted and weighted covariance matrix data.frame(uw = c(cov(xy)), select = c(cov(xy[wi == 1, ])), wg = c(covwt_stats$cov), row.names = c(sapply(colnames(cov(xy)), paste0, rownames(cov(xy)))) ) ## uw select wg ## xx 9.166667 2.5 2.5 ## xy 8.055556 -0.5 -0.5 ## yx 8.055556 -0.5 -0.5 ## yy 9.433333 1.7 1.7 Note how by weighting with a vector of 0 and 1s we are basically saying that the observations with a 0 will be excluded from the count. They are weighted to have 0 impact on the computation of the descriptive statistics. This is clear when you compare the results of the select and wg columns.\n 2.2 Computing the weighted covariance matrix manually We could replicate the results of the weighting simply by selecting a subset of the original data because all observations were either weighted 0 or equally (1). When this is not the case, weighting is slightly more complicated.\n2.2.1 Exploring the stats::cov.wt() function code Let‚Äôs look at how the cov.wt() function works more in depth. The internal code of the function is the following:\n# Examine the internal code of stats::cov.wt() --------------------------------- cov.wt ## function (x, wt = rep(1/nrow(x), nrow(x)), cor = FALSE, center = TRUE, ## method = c(\u0026#34;unbiased\u0026#34;, \u0026#34;ML\u0026#34;)) ## { ## if (is.data.frame(x)) ## x \u0026lt;- as.matrix(x) ## else if (!is.matrix(x)) ## stop(\u0026#34;\u0026#39;x\u0026#39; must be a matrix or a data frame\u0026#34;) ## if (!all(is.finite(x))) ## stop(\u0026#34;\u0026#39;x\u0026#39; must contain finite values only\u0026#34;) ## n \u0026lt;- nrow(x) ## if (with.wt \u0026lt;- !missing(wt)) { ## if (length(wt) != n) ## stop(\u0026#34;length of \u0026#39;wt\u0026#39; must equal the number of rows in \u0026#39;x\u0026#39;\u0026#34;) ## if (any(wt \u0026lt; 0) || (s \u0026lt;- sum(wt)) == 0) ## stop(\u0026#34;weights must be non-negative and not all zero\u0026#34;) ## wt \u0026lt;- wt/s ## } ## if (is.logical(center)) { ## center \u0026lt;- if (center) ## colSums(wt * x) ## else 0 ## } ## else { ## if (length(center) != ncol(x)) ## stop(\u0026#34;length of \u0026#39;center\u0026#39; must equal the number of columns in \u0026#39;x\u0026#39;\u0026#34;) ## } ## x \u0026lt;- sqrt(wt) * sweep(x, 2, center, check.margin = FALSE) ## cov \u0026lt;- switch(match.arg(method), unbiased = crossprod(x)/(1 - ## sum(wt^2)), ML = crossprod(x)) ## y \u0026lt;- list(cov = cov, center = center, n.obs = n) ## if (with.wt) ## y$wt \u0026lt;- wt ## if (cor) { ## Is \u0026lt;- 1/sqrt(diag(cov)) ## R \u0026lt;- cov ## R[] \u0026lt;- Is * cov * rep(Is, each = nrow(cov)) ## y$cor \u0026lt;- R ## } ## y ## } ## \u0026lt;bytecode: 0x7fd229e352d0\u0026gt; ## \u0026lt;environment: namespace:stats\u0026gt; Note the following:\n The first thing to pay attention to is that the function can compute the weighted covariance matrix in two ways:\n unbiased, using corssprod(x) / (1 - sum(wt^2)) ML (or maximum likelihood), using corssprod(x)  Note that the wt object is divided by the sum of the values it is storing, which amounts to normalising the weights. This happens with wt \u0026lt;- wt/s with s being created inside an if statement as s \u0026lt;- sum(wt).\n x is centered on the normalized weigthed means using the sweep function\n x is weighted by multiplying by sqrt(wt)\n   2.2.2 Reproducing the internal steps First, we‚Äôll set up a few objects we need to replicate manually what happens inside the stats::cov.wt() function. We need to define a dataset, a vector of weights, a method to compute descriptives, and based on these we will also create an object to store the number of rows (n). As a vector of weights we sample random values between 0 and 1. We can think of this as an attempt to weight each observation for the probability of sampling them from a population.\n# Set up manual computation of cov.wt() ‚Ä¶","date":1647216000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648903078,"objectID":"dfd82daeec56c4cfec7556dd9d2e1ebb","permalink":"https://symphonious-crostata-aa195e.netlify.app/post/covmatwt/","publishdate":"2022-03-14T00:00:00Z","relpermalink":"/post/covmatwt/","section":"post","summary":"1 Introduction 2 Learn by coding  2.1 Example 2.2 Computing the weighted covariance matrix manually  2.2.1 Exploring the stats::cov.wt() function code 2.2.2 Reproducing the internal steps  2.","tags":["statistics","weights","covariance"],"title":"Estimating the weighted covariance matrix in R","type":"post"},{"authors":["Edoardo Costantini (Edo)"],"categories":["Tutorials","Drafts"],"content":"   1 Introduction 2 Learn by coding  2.1 Fitting ridge regression manually  2.1.1 An alternative way to avoid penalising the intercept  2.2 Fit ridge regression with R packages  2.2.1 Use the biased estimation of variance 2.2.2 Return the unstandardized coefficients 2.2.3 Adjust the parametrization of \\(\\lambda\\) for glmnet 2.2.4 Compare manual and glmnet ridge regression output   3 TL;DR, just give me the code!   1 Introduction When there are many correlated variables in a linear regression model, their coefficients can become poorly determined and exhibit high variance. This problem is alleviated by imposing a size constraint (or penalty) on the coefficients.\nRidge regression shrinks the regression coefficients by imposing a penalty on their size. The ridge coefficients minimize a penalized residual sum of squares:\n\\[ \\hat{\\beta}^{\\text{ridge}} = \\text{argmin}_{\\beta} \\left\\{ \\sum_{i=1}^{N} \\left( y_i - \\beta_0 - \\sum_{j=1}^{p} x_{ij}\\beta_j \\right)^2 + \\lambda \\sum_{j=1}^{p}\\beta_j^2 \\right\\} \\]\nwith a one-to-one correspondence between the \\(\\sigma\\) and \\(t\\) parameters. The ridge solutions are not equivariant under scaling of the inputs Therefore, we better standardize the inputs before solving the minimization problem.\nNotice that the intercept \\(\\beta_0\\) has been left out of the penalty term. Penalization of the intercept would make the procedure depend on the origin chosen for \\(Y\\). By centering the predictors inputs, we can separate the solution to the minimazion problem into two parts:\n Intercept \\[ \\beta_0 = \\bar{y}=\\frac{1}{N}\\sum_{i = 1}^{N} y_i \\]\n Penalised regression coefficinets \\[ \\hat{\\beta}^{\\text{ridge}}=(\\mathbf{X}^T\\mathbf{X} + \\lambda \\mathbf{I})^{-1}\\mathbf{X}^Ty \\] which is the regular way of estimating regression coefficients with an added penalty term (\\(\\lambda \\mathbf{I}\\)) on the diagonal of the cross-product matrix (\\(\\mathbf{X}^T\\mathbf{X}\\)) to make it invertible (\\((...)^{-1}\\)).\n   2 Learn by coding First let‚Äôs set up the R environment. We‚Äôll use the glmnet to check how other people have implemented the same concepts. For these notes, we will work with the mtcars data. We will use the first column of the dataset (variable named mpg) as a dependent variable and the remaining ones as predictors.\n# Load packages library(glmnet) # Take the mtcars data y \u0026lt;- mtcars[, \u0026#34;mpg\u0026#34;] X \u0026lt;- mtcars[, -1] # Create a few shorthands we will use n \u0026lt;- nrow(X) p \u0026lt;- ncol(X) 2.1 Fitting ridge regression manually First, let‚Äôs fit ridge regression manually by separating the intercept and the regression coefficients estimation (two-step approach):\n# Scale the data (standardize) X_scale \u0026lt;- scale(X, center = TRUE, scale = TRUE) # Compute the cross-product matrix of the data XtX \u0026lt;- t(X_scale) %*% X_scale # Define the identify matrix I \u0026lt;- diag(ncol(X_scale)) # Define a lambda value lambda \u0026lt;- .1 # Estimate the regression coefficients with the ridge penalty bs_hat_r \u0026lt;- solve(XtX + lambda * I) %*% t(X_scale) %*% y # Estimate the intercept b0_hat_r \u0026lt;- mean(y) # Print the results round( data.frame(twostep = c(b0 = b0_hat_r, b = bs_hat_r)), 3 ) ## twostep ## b0 20.091 ## b1 -0.194 ## b2 1.366 ## b3 -1.373 ## b4 0.438 ## b5 -3.389 ## b6 1.361 ## b7 0.162 ## b8 1.243 ## b9 0.496 ## b10 -0.460 It is important to note the effect of centering and scaling. When fitting ridge regression, many sources reccomend to center the data. This allows to separate the estimation of the intercept from the estimation of the regression coefficients. As a result, only the regression coefficients are penalised. To understand the effect of centering, consider what happens in regular OLS estimation when predictors are centered:\n# Create a version of X that is centered X_center \u0026lt;- scale(X, center = TRUE, scale = FALSE) # Fit an regular linear model lm_ols \u0026lt;- lm(y ~ X_center) # Check that b0 is equal to the mean of y coef(lm_ols)[\u0026#34;(Intercept)\u0026#34;] - mean(y) ## (Intercept) ## -3.552714e-15 As for scaling, the important thing to not for now is that scaling allows the penalty term to act in the same way independently of the scale of the predictors.\n2.1.1 An alternative way to avoid penalising the intercept We can also avoid the penalisation of the intercept by setting to 0 the corresponding element in the pen object. By doing so, we can obtain the estimate of the intercept and the penalised regression coefficients in one step.\n # Create desing matrix with intercept X_scale_dm \u0026lt;- cbind(1, X_scale) # Compute cross-product matrix XtX \u0026lt;- crossprod(X_scale_dm) # Create penalty matrix pen \u0026lt;- lambda * diag(p + 1) pen[1] \u0026lt;- 0 # Obtain standardized estimates bs_hat_r2 \u0026lt;- solve(XtX + pen) %*% t(X_scale_dm) %*% (y) # Compare round( data.frame( twostep = c(b0 = b0_hat_r, b = bs_hat_r), onestep = drop(bs_hat_r2) ), 3 ) ## twostep onestep ## b0 20.091 20.091 ## b1 -0.194 -0.194 ## b2 1.366 1.366 ## b3 -1.373 -1.373 ## b4 0.438 0.438 ## b5 -3.389 -3.389 ## b6 1.361 1.361 ## b7 0.162 0.162 ## b8 1.243 1.243 ## b9 0.496 0.496 ## b10 -0.460 -0.460   2.2 Fit ‚Ä¶","date":1646006400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648902417,"objectID":"002b3ab0e0f6e5e68210162d4766a05b","permalink":"https://symphonious-crostata-aa195e.netlify.app/post/ridge/","publishdate":"2022-02-28T00:00:00Z","relpermalink":"/post/ridge/","section":"post","summary":"1 Introduction 2 Learn by coding  2.1 Fitting ridge regression manually  2.1.1 An alternative way to avoid penalising the intercept  2.2 Fit ridge regression with R packages  2.","tags":["statistics","regression","penalty","high-dimensional data"],"title":"Estimating ridge regression in R","type":"post"},{"authors":["Edoardo Costantini (Edo)"],"categories":null,"content":" Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"https://symphonious-crostata-aa195e.netlify.app/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  **Two**  Three   A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}}   Custom CSS Example Let‚Äôs make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://symphonious-crostata-aa195e.netlify.app/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"https://symphonious-crostata-aa195e.netlify.app/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"https://symphonious-crostata-aa195e.netlify.app/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":["Edoardo Costantini (Edo)","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"https://symphonious-crostata-aa195e.netlify.app/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["Edoardo Costantini (Edo)","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"https://symphonious-crostata-aa195e.netlify.app/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://symphonious-crostata-aa195e.netlify.app/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]